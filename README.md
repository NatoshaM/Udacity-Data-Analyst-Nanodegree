**Data-Analyst-Nanodegree**

***
Udacity Data Analyst Nanodegree teaches you how to to clean up messy data, uncover patterns and insights, and communicate your findings. You'll start with an introduction to data analysis tools, including Jupyter Notebook, NumPy, pandas, and Matplotlib. Using these tools, you will ask questions about data and answer them through data collection, exploration, wrangling, and visualization. This intermediate-level program includes real-world projects where you will choose your own datasets, research questions, and analysis approach. As you progress through the program, each course will repeat the data analysis process while introducing
more advanced techniques, such as applying data imputation to fill in missing data and applying appropriate encodings when developing data visualizations.  (DAND) course repository included projects on Medical No shows prediction, Regression, Hypothesis test , A/B test, Data Wrangling(gather, assess, clean), and Data Visualization.

You can take the course on Uacity https://www.udacity.com/

This course repository included projects on predictions, Regression, Hypothesis test , A/B test, Data Wrangling(gather, assess, clean), and Data Visualization.

***

ðŸŽ¬[**Project 1: TMDb Movie Analysis**](https://github.com/NatoshaM/Udacity-Data-Analyst-Nanodegree/blob/main/Project%201%20_TMDb%20Movie%20Data%20Analysis/Investigate_a_Dataset.ipynb)

Analysing more than 10,000 TMDb movies and getting the answers to: 

What are the top 10 favorite movies? 

What year was the highest budget movie produce? 

What is the correlation between the average runtime of movies and the passage of time?

***

[**Project 2: Analyze A/B Test Results**](https://github.com/NatoshaM/Udacity-Data-Analyst-Nanodegree/blob/main/Project%202_%20AB%20Testing/Analyze_ab_test_results_notebook_new.ipynb)

A/B tests are very commonly performed by data analysts and data scientists. For this project, we will be working to understand the results of an A/B test run by an e-commerce website. The company has developed a new web page in order to try and increase the number of users who "convert," meaning the number of users who decide to pay for the company's product. The goal is to  help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.


***

**Project 3: R Programming**

Using R for statistical analysis

***

[**Project 4: Data Wrangling**](https://github.com/NatoshaM/Udacity-Data-Analyst-Nanodegree/blob/main/Project%204_Data%20Wrangling/Data_Wrangling_Project_Template.ipynb)

In this project, you will apply the skills you acquired in the course to gather and wrangle real-world data with two datasets of your choice.

You will retrieve and extract the data, assess the data programmatically and visually, accross elements of data quality and structure, and implement a cleaning strategy for the data. You will then store the updated data into your selected database/data store, combine the data, and answer a research question with the datasets.

***

[**Project 5: Data Modeling with Postgres**](https://github.com/NatoshaM/Udacity-Data-Analyst-Nanodegree/blob/main/Project%205_Data%20Modeling%20with%20Postgres/etl.ipynb)


A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs users are listening to. Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app.

They'd like a data engineer to create a Postgres database with tables designed to optimize queries on song play analysis, and bring you on the project. Your role is to create a database schema and ETL pipeline for this analysis. You'll be able to test your database and ETL pipeline by running queries given to you by the analytics team from Sparkify and compare your results with their expected results.

**Project Description**

In this project, you'll apply what you've learned on data modeling with Postgres and build an ETL pipeline using Python. To complete the project, you will need to define fact and dimension tables for a star schema for a particular analytic focus, and write an ETL pipeline that transfers data from files in two local directories into these tables in Postgres using Python and SQL.

***

**Project 6: Data Visualizations using Tableau**

The goal in this project is to create visualizations and Dashboards in Tableau to reveal insights from a data set. You will create data visualizations that tell a story or highlight patterns in the data set. Your work should be a reflection of the theory and practice of data visualization, such as visual encodings, design principles, and effective communication.

***

[**Poject 7: Machine Learning_ Supervised Learning**](https://github.com/NatoshaM/Udacity-Data-Analyst-Nanodegree/blob/main/Project_7%20Machine%20Learning_%20Supervised%20Learning/finding_donors.ipynb)

This project is designed to get you acquainted with the many supervised learning algorithms available in sklearn, and to also provide for a method of evaluating just how each model works and performs on a certain type of data. It is important in machine learning to understand exactly when and where a certain algorithm should be used, and when one should be avoided.

**Things you will learn by completing this project:**

How to identify when preprocessing is needed, and how to apply it.
How to establish a benchmark for a solution to the problem.
What each of several supervised learning algorithms accomplishes given a specific dataset.
How to investigate whether a candidate solution model is adequate for the problem.

**Description**

CharityML is a fictitious charity organization located in the heart of Silicon Valley that was established to provide financial support for people eager to learn machine learning. After nearly 32,000 letters were sent to people in the community, CharityML determined that every donation they received came from someone that was making more than $50,000 annually. To expand their potential donor base, CharityML has decided to send letters to residents of California, but to only those most likely to donate to the charity. With nearly 15 million working Californians, CharityML has brought you on board to help build an algorithm to best identify potential donors and reduce overhead cost of sending mail. Your goal will be evaluate and optimize several different supervised learners to determine which algorithm will provide the highest donation yield while also reducing the total number of letters being sent.

***

[**Project 8: Machine Learning_Unsupervised Learning**](https://github.com/NatoshaM/Udacity-Data-Analyst-Nanodegree/blob/main/Project_8%20Machine%20Learning_Unsupervised%20Learning/Identify_Customer_Segments%20.ipynb)


The unsupervised learning branch of machine learning is key in the organization of large and complex datasets. While unsupervised learning lies in contrast to supervised learning in the fact that unsupervised learning lacks objective output classes or values, it can still be important in converting the data into a form that can be used in a supervised learning task. Dimensionality reduction techniques can help surface the main signals and associations in your data, providing supervised learning techniques a more focused set of features upon which to apply for their work. Clustering techniques are useful for understanding how the data points themselves are organized. These clusters might themselves be a useful feature in a directed supervised learning task. This project will give you hands-on experience with a real-life task that makes use of these techniques, focusing on the unsupervised work that goes into understanding a dataset.

In addition, the dataset presented in this project requires a number of assessment and cleaning steps before you can apply your machine learning methods. In workplace contexts, you will frequently need to work with data that is untidy or needs preprocessing before standard algorithms and models can be applied. The ability to perform data wrangling and the ability to make decisions on data that you work with are both valuable skills that you will practice in this project.

[**Project 9: Machine Learning DevOps_Building a Pipeline]

You are working for a property management company renting rooms and properties for short periods of time on various platforms. You need to estimate the typical price for a given property based on the price of similar properties. Your company receives new data in bulk every week. The model needs to be retrained with the same cadence, necessitating an end-to-end pipeline that can be reused.

In this project, you will build a pipeline

[**Project 10: Maching Learning DevOps_Develop a Classification Model]

In this project, you will develop a classification model on publicly available Census Bureau data. You will also write code to monitor the model performance on various data slices. Then, you will deploy your model using the FastAPI package.

Here is an overview of the project steps:

  * Set up GitHub Action
  * Understand the data
  * Build a machine learning model
  * Construct a machine learning pipeline
  * Unit test the model
  * Create a RESTful API
  * Push the changes to the GitHub repo
